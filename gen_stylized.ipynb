{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "import os, cv2\n",
    "import argparse\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "import sys,os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"-1\"\n",
    "\n",
    "style='watercolor'\n",
    "\n",
    "model_id = 'damo/cv_cartoon_stable_diffusion_' + style\n",
    "pipe = pipeline(Tasks.text_to_image_synthesis, model=model_id,\n",
    "                    model_revision='v1.0.0', torch_dtype=torch.float16)\n",
    "from diffusers.schedulers import EulerAncestralDiscreteScheduler\n",
    "pipe.pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.pipeline.scheduler.config)\n",
    "print('model init finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_name = 'Taylor Swift'\n",
    "prompt = 'sks style, a painting of a %s, no text'%(celeb_name)\n",
    "\n",
    "repeat_num=4\n",
    "\n",
    "images =  pipe({'text': prompt, 'num_images_per_prompt': repeat_num})['output_imgs']\n",
    "\n",
    "dst_dir = './data/debug'\n",
    "for i,image in enumerate(images):\n",
    "    plt.figure()\n",
    "    plt.imshow(image[:,:,::-1])\n",
    "    dst_fn = 'ts_%s_%d.png'%(style,i)\n",
    "\n",
    "    cv2.imwrite(os.path.join(dst_dir,dst_fn), image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from source.facelib.facer import FaceAna\n",
    "import source.utils as utils\n",
    "from source.mtcnn_pytorch.src.align_trans import warp_and_crop_face, get_reference_facial_points\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "import sys,os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"-1\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_HOME']=\"/usr/local/cuda\"\n",
    "\n",
    "\n",
    "class FaceProcesser:\n",
    "    def __init__(self, dataroot, crop_size=256, max_face=1):\n",
    "        self.max_face = max_face\n",
    "        self.crop_size = crop_size\n",
    "        self.facer = FaceAna(dataroot)\n",
    "\n",
    "    def filter_face(self, lm, crop_size):\n",
    "        a = max(lm[:, 0])-min(lm[:, 0])\n",
    "        b = max(lm[:, 1])-min(lm[:, 1])\n",
    "        # print(\"a:%d, b:%d\"%(a,b))\n",
    "        if max(a, b) < int(crop_size*0.3):  # 眼间距 ？ 70\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def process(self, img):\n",
    "\n",
    "        warped_face = None\n",
    "        h, w, c = img.shape\n",
    "        if c == 4:\n",
    "            img_bgr = img[:, :, :3]\n",
    "        else:\n",
    "            img_bgr = img\n",
    "\n",
    "        src_img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        boxes, landmarks, _ = self.facer.run(src_img)\n",
    "\n",
    "        if boxes.shape[0] == 0:\n",
    "            print('No face detected!')\n",
    "            return warped_face\n",
    "\n",
    "        # process all faces\n",
    "        warped_faces = []\n",
    "        i = 0\n",
    "\n",
    "        for landmark in landmarks:\n",
    "            if self.max_face and i > 0:\n",
    "                continue\n",
    "\n",
    "            if self.filter_face(landmark, self.crop_size) == 0:\n",
    "                print(\"filtered!\")\n",
    "                continue\n",
    "\n",
    "            f5p = utils.get_f5p(landmark, img_bgr)\n",
    "            # face alignment\n",
    "            warped_face, _ = warp_and_crop_face(\n",
    "                img_bgr,\n",
    "                f5p,\n",
    "                ratio=0.75,\n",
    "                reference_pts=get_reference_facial_points(default_square=True),\n",
    "                crop_size=(self.crop_size, self.crop_size),\n",
    "                return_trans_inv=True)\n",
    "\n",
    "            warped_faces.append(warped_face)\n",
    "            i = i+1\n",
    "\n",
    "        return warped_faces\n",
    "\n",
    "\n",
    "crop_size=256\n",
    "max_face=1\n",
    "model_dir = 'damo/cv_unet_person-image-cartoon_compound-models'\n",
    "processer = FaceProcesser(\n",
    "        dataroot=model_dir, crop_size=crop_size, max_face=max_face)\n",
    "\n",
    "# warped_faces = processer.process(images[0])\n",
    "\n",
    "src_dir ='data/debug'\n",
    "src_img_ls = os.listdir(src_dir)\n",
    "for image_fn in src_img_ls:\n",
    "    image = cv2.imread(os.path.join(src_dir,image_fn))\n",
    "    img_h, img_w, _ = image.shape\n",
    "    warped_faces = processer.process(image)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(warped_faces[:,:,::-1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(warped_faces[0][:,:,::-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dctnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
